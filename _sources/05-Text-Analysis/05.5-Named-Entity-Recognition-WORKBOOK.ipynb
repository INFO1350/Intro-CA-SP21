{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition — Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to learn about a text analysis method called *Named Entity Recognition* (NER). This method will help us computationally identify people, places, and things (of various kinds) in a text or collection of texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install spaCy and Download Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to download the English-language model (`en_core_web_sm`), which will be processing and making predictions about our texts. This is the model that was trained on the annotated \"OntoNotes\" corpus. You can download the `en_core_web_sm` model by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (20.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (50.3.2)\n",
      "Requirement already satisfied: wheel in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (0.34.2)\n",
      "Collecting pip\n",
      "  Using cached pip-21.0.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-56.0.0-py3-none-any.whl (784 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 50.3.2\n",
      "    Uninstalling setuptools-50.3.2:\n",
      "      Successfully uninstalled setuptools-50.3.2\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.3.3\n",
      "    Uninstalling pip-20.3.3:\n",
      "      Successfully uninstalled pip-20.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.1.0 requires wrapt>=1.11.1, which is not installed.\n",
      "tensorboard 2.1.1 requires werkzeug>=0.11.15, which is not installed.\n",
      "mordecai 2.0.3 requires h5py>=2.6.0, which is not installed.\n",
      "tensorflow 2.1.0 requires scipy==1.4.1; python_version >= \"3\", but you have scipy 1.5.4 which is incompatible.\n",
      "myst-parser 0.13.0 requires markdown-it-py~=0.6.0, but you have markdown-it-py 0.5.8 which is incompatible.\n",
      "myst-nb 0.10.1 requires myst-parser~=0.12.9, but you have myst-parser 0.13.0 which is incompatible.\n",
      "mordecai 2.0.3 requires spacy<2.1.0,>=2.0.3, but you have spacy 2.2.4 which is incompatible.\u001b[0m\n",
      "Successfully installed pip-21.0.1 setuptools-56.0.0 wheel-0.36.2\n",
      "Requirement already satisfied: spacy in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (2.2.4)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp37-cp37m-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.2\n",
      "  Downloading thinc-8.0.2-cp37-cp37m-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.11.2)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.23.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Downloading spacy_legacy-3.0.2-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.1-cp37-cp37m-macosx_10_9_x86_64.whl (449 kB)\n",
      "\u001b[K     |████████████████████████████████| 449 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (20.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.7.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (4.46.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.2-py3-none-any.whl (9.6 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: setuptools in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy) (56.0.0)\n",
      "Collecting importlib-metadata>=0.20\n",
      "  Downloading importlib_metadata-3.2.0-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20->spacy) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.14.0)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=7f661d1923ddc0565aa377d8cf6489269dcf8d3c1005c4550ba5151dbbc5b437\n",
      "  Stored in directory: /Users/melaniewalsh/Library/Caches/pip/wheels/83/a6/12/bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\n",
      "Successfully built smart-open\n",
      "Installing collected packages: importlib-metadata, catalogue, wasabi, typer, srsly, smart-open, pydantic, thinc, spacy-legacy, pathy, spacy\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.9.1\n",
      "    Uninstalling importlib-metadata-3.9.1:\n",
      "      Successfully uninstalled importlib-metadata-3.9.1\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 0.6.0\n",
      "    Uninstalling wasabi-0.6.0:\n",
      "      Successfully uninstalled wasabi-0.6.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.2\n",
      "    Uninstalling srsly-1.0.2:\n",
      "      Successfully uninstalled srsly-1.0.2\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 5.0.0\n",
      "    Uninstalling smart-open-5.0.0:\n",
      "      Successfully uninstalled smart-open-5.0.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 7.4.0\n",
      "    Uninstalling thinc-7.4.0:\n",
      "      Successfully uninstalled thinc-7.4.0\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 2.2.4\n",
      "    Uninstalling spacy-2.2.4:\n",
      "      Successfully uninstalled spacy-2.2.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mordecai 2.0.3 requires h5py>=2.6.0, which is not installed.\n",
      "virtualenv 20.0.31 requires importlib-metadata<2,>=0.12; python_version < \"3.8\", but you have importlib-metadata 3.2.0 which is incompatible.\n",
      "tox 3.20.0 requires importlib-metadata<2,>=0.12; python_version < \"3.8\", but you have importlib-metadata 3.2.0 which is incompatible.\n",
      "myst-nb 0.10.1 requires myst-parser~=0.12.9, but you have myst-parser 0.13.0 which is incompatible.\n",
      "mordecai 2.0.3 requires spacy<2.1.0,>=2.0.3, but you have spacy 3.0.5 which is incompatible.\n",
      "keyring 23.0.1 requires importlib-metadata>=3.6, but you have importlib-metadata 3.2.0 which is incompatible.\u001b[0m\n",
      "Successfully installed catalogue-2.0.2 importlib-metadata-3.2.0 pathy-0.4.0 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.2 srsly-2.4.1 thinc-8.0.2 typer-0.3.2 wasabi-0.8.2\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: entry_points() got an unexpected keyword argument 'group'\u001b[0m\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.2)\n",
      "Requirement already satisfied: jinja2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.1)\n",
      "Requirement already satisfied: setuptools in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (56.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.46.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.20.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.0)\n",
      "Requirement already satisfied: six in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.9)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/melaniewalsh/opt/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.2.5\n",
      "    Uninstalling en-core-web-sm-2.2.5:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.5\n",
      "Successfully installed en-core-web-sm-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to import `spacy` and `displacy`, a special spaCy module for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to import the `Counter` module for counting people, places, and things, and the `pandas` library for organizing and displaying data (we're also changing the pandas default max row and column width display setting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: spaCy offers [models for other languages](https://spacy.io/usage/models#languages) including German, French, Spanish, Portuguese, Italian, Dutch, Greek, Norwegian, and Lithuanian. Languages such as Russian, Ukrainian, Thai, Chinese, Japanese, Korean and Vietnamese don't currently have their own NLP models. However, spaCy offers language and tokenization support for many of these language with external dependencies — such as [PyviKonlpy](https://github.com/konlpy/konlpy) for Korean or [Jieba](https://github.com/fxsjy/jieba) for Chinese.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 600\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is downloaded, we need to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we open and read Ada Lovelace's obituary. Then we run`nlp()` on the text and create our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../texts/literature/House-on-Mango-Street/04-My-Name.txt\"\n",
    "text = open(filepath, encoding='utf-8').read()\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a Named Entities chart taken from [spaCy's website](https://spacy.io/api/annotation#named-entities), which shows the different named entities that spaCy can identify as well as their corresponding type labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|PERSON|People, including fictional.|\n",
    "|NORP|Nationalities or religious or political groups.|\n",
    "|FAC|Buildings, airports, highways, bridges, etc.|\n",
    "|ORG|Companies, agencies, institutions, etc.|\n",
    "|GPE|Countries, cities, states.|\n",
    "|LOC|Non-GPE locations, mountain ranges, bodies of water.|\n",
    "|PRODUCT|Objects, vehicles, foods, etc. (Not services.)|\n",
    "|EVENT|Named hurricanes, battles, wars, sports events, etc.|\n",
    "|WORK_OF_ART|Titles of books, songs, etc.|\n",
    "|LAW|Named documents made into laws.|\n",
    "|LANGUAGE|Any named language.|\n",
    "|DATE|Absolute or relative dates or periods.|\n",
    "|TIME|Times smaller than a day.|\n",
    "|PERCENT|Percentage, including ”%“.|\n",
    "|MONEY|Monetary values, including unit.|\n",
    "|QUANTITY|Measurements, as of weight or distance.|\n",
    "|ORDINAL|“first”, “second”, etc.|\n",
    "|CARDINAL|Numerals that do not fall under another type.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly see spaCy's NER in action, we can use the [spaCy module `displacy`](https://spacy.io/usage/visualizers#ent) with the `style=` parameter set to \"ent\"  (short for entities):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My Name</br></br></br>In \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    English\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " my name means hope. In \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Spanish\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " it means too many letters. It means sadness, it means waiting. It is like the number \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ". A muddy color. It is the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mexican\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " records my father plays on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sunday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mornings\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " when he is shaving, songs like sobbing.</br></br>It was my great-grandmother’s name and now it is mine. She was a horse woman too, born like me in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Chinese year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of the horse—which is supposed to be bad luck if you’re born female—but I think this is a \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " lie because the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", like the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mexicans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", don’t like their women strong.</br></br>My great-grandmother. I would’ve liked to have known her, a wild horse of a woman, so wild she wouldn’t marry. Until my great-grandfather threw a sack over her head and carried her off. Just like that, as if she were a fancy chandelier. That’s the way he did it.</br></br>And the story goes she never forgave him. She looked out the window her whole life, the way so many women sit their sadness on an elbow. I wonder if she made the best with what she got or was she sorry because she couldn’t be all the things she wanted to be. Esperanza. I have inherited her name, but I don’t want to inherit her place by the window.</br></br>At school they say my name funny as if the syllables were made out of tin and hurt the roof of your mouth. But in \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Spanish\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " my name is made out of a softer something, like silver, not quite as thick as sister’s name—\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Magdalena\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "—which is uglier than mine. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Magdalena\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " who at least can come home and become \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nenny\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". But I am always \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Esperanza\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</br></br>I would like to baptize myself under a new name, a name more like the real me, the one nobody sees. Esperanza as Lisandra or Maritza or Zeze the X. Yes. Something like Zeze the X will do.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(document, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the named entities in our `document` can be found in the `document.ents` property. If we check out `document.ents`, we can see all the entities from Ada Lovelace's obituary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(English,\n",
       " Spanish,\n",
       " nine,\n",
       " Mexican,\n",
       " Sunday,\n",
       " mornings,\n",
       " the Chinese year,\n",
       " Chinese,\n",
       " Chinese,\n",
       " Mexicans,\n",
       " Spanish,\n",
       " Magdalena,\n",
       " Magdalena,\n",
       " Nenny,\n",
       " Esperanza)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the named entities in `document.ents` contains [more information about itself](https://spacy.io/usage/linguistic-features#accessing), which we can access by iterating through the `document.ents` with a simple `for` loop.\n",
    "\n",
    "For each `named_entity` in `document.ents`, we will extract the `named_entity` and its corresponding `named_entity.label_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English LANGUAGE\n",
      "Spanish NORP\n",
      "nine CARDINAL\n",
      "Mexican NORP\n",
      "Sunday DATE\n",
      "mornings TIME\n",
      "the Chinese year DATE\n",
      "Chinese NORP\n",
      "Chinese NORP\n",
      "Mexicans NORP\n",
      "Spanish LANGUAGE\n",
      "Magdalena PERSON\n",
      "Magdalena PERSON\n",
      "Nenny PERSON\n",
      "Esperanza PERSON\n"
     ]
    }
   ],
   "source": [
    "for named_entity in document.ents:\n",
    "    print(named_entity, named_entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract just the named entities that have been identified as `PERSON`, we can add a simple `if` statement into the mix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magdalena\n",
      "Magdalena\n",
      "Nenny\n",
      "Esperanza\n"
     ]
    }
   ],
   "source": [
    "for named_entity in document.ents:\n",
    "    if named_entity.label_ == \"PERSON\":\n",
    "        print(named_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!\n",
    "## NER with The House on Mango Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"../texts/literature/The-House-on-Mango-Street-Sandra-Cisneros.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get People"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|PERSON|People, including fictional.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract and count the people, we will use an `if` statement that will pull out words only if their \"ent\" label matches \"PERSON.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "\n",
    "for named_entity in document.ents:\n",
    "    # Your Code Here\n",
    "        #Your Code Here\n",
    "\n",
    "people_tally = Counter(people)\n",
    "\n",
    "df = pd.DataFrame(people_tally.most_common(), columns=['character', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|GPE|Countries, cities, states.|\n",
    "|LOC|Non-GPE locations, mountain ranges, bodies of water.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract and count places, we can follow the same model as above, except we will change our `if` statement to check for \"ent\" labels that match \"GPE\" or \"LOC.\" These are the type labels for \"counties cities, states\" and \"locations, mountain ranges, bodies of water.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "\n",
    "for named_entity in document.ents:\n",
    "    # Your Code Here\n",
    "        # Your Code Here\n",
    "\n",
    "places_tally = Counter(places)\n",
    "\n",
    "df = pd.DataFrame(places_tally.most_common(), columns=['place', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|WORK_OF_ART|Titles of books, songs, etc.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract and count works of art, we can follow a similar-ish model to the examples above. This time, however, we're going to make our code even more economical and efficient (while still changing our `if` statement to match the \"ent\" label \"WORK_OF_ART\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "languages = []\n",
    "\n",
    "for named_entity in document.ents:\n",
    "    # Your Code Here\n",
    "        # Your Code Here\n",
    "\n",
    "languages_tally = Counter(languages)\n",
    "\n",
    "df = pd.DataFrame(languages_tally.most_common(), columns = ['language', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Another Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|PERSON|People, including fictional.|\n",
    "|NORP|Nationalities or religious or political groups.|\n",
    "|FAC|Buildings, airports, highways, bridges, etc.|\n",
    "|ORG|Companies, agencies, institutions, etc.|\n",
    "|GPE|Countries, cities, states.|\n",
    "|LOC|Non-GPE locations, mountain ranges, bodies of water.|\n",
    "|PRODUCT|Objects, vehicles, foods, etc. (Not services.)|\n",
    "|EVENT|Named hurricanes, battles, wars, sports events, etc.|\n",
    "|WORK_OF_ART|Titles of books, songs, etc.|\n",
    "|LAW|Named documents made into laws.|\n",
    "|LANGUAGE|Any named language.|\n",
    "|DATE|Absolute or relative dates or periods.|\n",
    "|TIME|Times smaller than a day.|\n",
    "|PERCENT|Percentage, including ”%“.|\n",
    "|MONEY|Monetary values, including unit.|\n",
    "|QUANTITY|Measurements, as of weight or distance.|\n",
    "|ORDINAL|“first”, “second”, etc.|\n",
    "|CARDINAL|Numerals that do not fall under another type.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would NER be good for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
